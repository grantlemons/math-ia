\documentclass{paper}

%Document Info
\newcommand{\thetitle}{Methods of Adaptive Quadrature}
\newcommand{\researchquestion}{Comparing a new method of adaptive quadrature to an existing strategy.}
\newcommand{\theauthor}{Grant Lemons}

%Random imports
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{XCharter}
\usepackage{fancyhdr}
\usepackage{subfiles}
\usepackage[section]{placeins}
\usepackage[width=.95\textwidth, font={footnotesize}]{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage[all]{nowidow}
\usepackage[nameinlink, noabbrev, capitalize]{cleveref}

%Needspace
\usepackage{needspace}
\AddToHook{cmd/section/before}{\Needspace*{3\baselineskip}}

% Specific Hyphenation
\hyphenation{Simpson}

% Bibliography
\usepackage[backend=biber, notes, sorting=cms, legalnotes=false]{biblatex-chicago}
\usepackage{fnpct}
\addbibresource{bibliography.bib}
\usepackage[bottom]{footmisc}

%Code Snippets
\usepackage{minted}
\usepackage{xcolor}
\usemintedstyle{bw}
\usepackage{fontspec}
\setmonofont[
    Path=/usr/share/fonts/TTF/,
    Contextuals={Alternate},
    UprightFont = FiraCode-Regular,
    BoldFont = FiraCode-Bold,
    Extension=.ttf
]{FiraCode}
\setlength\partopsep{-\topsep}
\addtolength\partopsep{-\parskip}
\addtolength\partopsep{0.5cm}

%List of Snippets
\usepackage{tocloft}
\newcommand{\listsnippets}{List of Code Snippets}
\newlistof{snippet}{snip}{\listsnippets}
\newcommand{\snippet}[1]{%
    \refstepcounter{snippet}
    \addcontentsline{snip}{snippet}{\protect\numberline{\thesnippet}#1}\par}
\usepackage{tocbibind}
\newcommand{\listofsnippets}{
    \begingroup
        \tocfile{\listsnippets}{snip}
    \endgroup
}
\renewcommand\cftsnippetindent{\cftfigindent}

%Tikz
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{patterns}
\usetikzlibrary{fpu}
\usetikzlibrary{spy}

%Tikz Graphs
\newcommand{\exampleLowSubintervals}{6}
\newcommand{\exampleHighSubintervals}{60}
\newcommand{\ruleEq}[1]{cos(#1 r)+1}
\newcommand{\simpleEq}[1]{((#1+(2/3))^3 + 2*(#1)^2)/6}
\newcommand{\complexEq}[1]{2*(sin((3)/(abs(#1)+.3) r)^2)}
\newcommand{\normalEq}[1]{(10/sqrt(2*pi))*e^((-1/2)*((#1)^2))}
\newcommand{\DerDerNormalEq}[1]{(\normalEq{#1})*((#1)^2 - 1)}
\newcommand{\graphRule}{\draw[darkgray, smooth, thick, samples=100, domain={\leftbound-.05}:{\rightbound+.05}] plot(\x, {\ruleEq{\x}}) node[darkgray, align=left, right, yshift=0.5cm, xshift=-3.9cm] {\scriptsize \(f(x)\)};}
\newcommand{\graphSimple}{\draw[darkgray, smooth, thick, samples=100, domain={\leftbound-.05}:{\rightbound+.05}] plot(\x, {\simpleEq{\x}}) node[darkgray, align=left, right, yshift=-0.2cm, xshift=-3.0cm] {\tiny\(f(x)\)};}
\newcommand{\graphComplex}{\draw[darkgray, smooth, thick, samples=1500, domain={\leftbound-.05}:{\rightbound+.05}] plot(\x, {\complexEq{\x}}) node[darkgray, align=left, right, yshift=.15cm, xshift=-3.6cm] {\tiny\(f(x)\)};}
\newcommand{\graphNormal}{\draw[darkgray, smooth, thick, samples=100, domain={\leftbound-.05}:{\rightbound+.05}] plot(\x, {\normalEq{\x}}) node[darkgray, align=left, right, yshift=2.5cm, xshift=-3cm] {\small\(f(x)\)};}
\newcommand{\graphDerDerNormal}{\draw[dashed, darkgray, smooth, thick, samples=100, domain={\leftbound-.05}:{\rightbound+.05}] plot(\x, {\DerDerNormalEq{\x}}) node[darkgray, align=left, right, yshift=-1.5cm, xshift=-3.3cm] {\small\(\sder{f(x)}\)};}


%Page Numbering
\usepackage{lastpage}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage of \pageref{LastPage}}
\setlength{\headheight}{15pt}

%Equation Numbering
\newcommand*\tageq{\refstepcounter{equation}\tag{\theequation}}

%Derivative commands
\newcommand{\der}[1]{\dfrac{d}{dx}\left[#1\right]}
\newcommand{\sder}[1]{\dfrac{d^2}{dx^2}\left[#1\right]}

\begin{document}
\insertTitlePage
\tableofcontents
\thispagestyle{empty}
\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\section{Introduction}
\label{sec:intro}
Integration is the process of calculating the area enclosed by a function (known as the integrand) over an inverval.
This process is often done by hand using the Fundamental Theorem of Calculus, but can also by conducted by a computer.
The means by which a computer conducts this operation is through a process called quadrature (also known as numerical integration).
Quadrature is the process of fitting shapes of a known area to the integrand in order to closely approximate the area enclosed by the integrand.
This often involves splitting the interval into smaller \textit{subintervals}, and summing the approximate areas of each.
In the most basic methods of quadrature, these subintervals are of a fixed width, but it is possible to use subintervals of varying widths for the sake of computational efficiency.
This is known as Adaptive Quadrature, and can be accomplished in a variety of ways.
This paper seeks to compare an existing method of adaptive quadrature to one of my own design, and examine the effectiveness and efficiency of the two methods.

My interest in this topic was sparked when we first covered integrals in our IB AA SL coursework.
In class we only covered two methods of quadrature, the \hyperref[sec:rect_rule]{Rectangle} and \hyperref[sec:trap_rule]{Trapezoid} Rules, but through consulting with my teacher and self-study, I quickly learned all about advanced methods such as \hyperref[sec:smps_rule]{Simpson's 1/3} and 3/8 Rules.
I didn't have the opportunity to channel this passion until the IA, but have used this opportunity to deepen my knowledge of the means by which advanced methods operate and the pros and cons of different quadrature rules.
I also used this opportunity to include one of my passions, computer science, applying it in a useful manner to contribute to my understanding and this investigation.

\newpage % Not including this devotes whole pages to graphs

\section{Background}
\label{sec:background}
\subsection{Rectangle Rule}
\label{sec:rect_rule}
The most basic method---or rule---used in quadrature is splitting the interval into smaller subintervals and fitting rectangles beneath the curve.
The height of each rectangle is based on the value of the function at one of its subinterval's bounds, which makes area easy to approximate to a reasonable degree of accuracy as shown by \cref{fig:rect_rule}.
Since the area of a rectangle is extremely easy to calculate~(see \cref{eqn:rect_area}), this method is simple to implement over the entire function by summing the areas of each subinterval as demonstrated in \cref{eqn:rect_rule}.
%
\begin{equation}
    \label{eqn:rect_area}
    A = l \cdot w
\end{equation}
\begin{equation}
    \label{eqn:rect_rule}
    \int_a^b f(x) dx \approx \sum_{j=1}^n (x_{j-1} - x_i) \cdot f(x_i + x_{j+1})
\end{equation}
%
\subfile{graphs/rules/rect_rule}
%
\subsection{Trapezoid Rule}
\label{sec:trap_rule}
An alternative means typically used in place of this method utilizes trapezoids instead of rectangles.
Instead of picking a single point at which to base the height on, the trapezoid rule utilizes the value of the function at both the left and right bounds, and uses them to approximate a trapezoid under the curve.
The equation for the Trapezoid Rule~(see \cref{eqn:trap_rule}) is only marginally more complicated than that of the Rectangle Rule~(see \cref{eqn:rect_rule}), but fits functions more closely, which provides significantly more accuracy as can be observed in in \cref{fig:trap_rule}.
%
\begin{equation}
    \label{eqn:trap_rule}
    \int_a^b f(x) dx \approx \dfrac{b - a}{2n} \sum_{j=1}^n (f(x_{j-1})+f(x_{j}))
\end{equation}
%
\subfile{graphs/rules/trap_rule}
%
\subsection{Composite Simpson's 1/3 Rule}
\label{sec:smps_rule}
Beyond these simple methods, other techniques use polynomials in an attempt to fit the curve as closely as possible.
One such method is the Composite Simpson's 1/3 rule, which uses the left, right, and, mid-interval values of each subinterval to construct a polynomial.
The use of polynomials allows the Composite Simpson's 1/3 rule to approximate the complex integrand with easily integrable functions that fit the integrand extremely closely as shown in \cref{fig:smps_rule}.
%
\subfile{graphs/rules/smps_rule}
%
Lagrange Polynomial Interpolation~(see \cref{eqn:lagrange}) is a means of constructing a polynomial that passes through a set of points.
In Simpson's 1/3 Rule, this method is used to construct more easily integrated polynomials (as demonstrated in \cref{eqn:lagrange_smps}), using the \(x\) and \(y\) values of the left-bound, right-bound, and mid-interval values of the subinterval.
%
\begin{equation}
    \label{eqn:lagrange}
    P(x) = \sum_{j=1}^n y_j \prod_{\substack{k = 1 \\ k \neq j}}^n \dfrac{x - x_k}{x_j - x_k}
\end{equation}
%
Expanding \cref{eqn:lagrange} with the points \(m\), \(a\), and \(b\) for midpoint, left-bound, and right-bounds respectively produces \cref{eqn:lagrange_smps}.
%
\begin{equation}
    \label{eqn:lagrange_smps}
    P(x) = f(a) \dfrac{(x - m)(x - b)}{(a - m)(a - b)} + f(m) \dfrac{(x - a)(x - b)}{(m - a)(m - b)} + f(b) \dfrac{(x - a)(x - m)}{(b - a)(b - m)}
\end{equation}
%
As \(m\) represents the midpoint \((a + b) / 2\), this can be restated in terms of \(a\) and \(b\) as demonstrated in \cref{eqn:lagrange_smps_ab}.
%
\begin{equation}
    \label{eqn:lagrange_smps_ab}
    \resizebox{.9\textwidth}{!} 
    {
    $P(x) = f(a) \dfrac{\left(x - \dfrac{a+b}{2}\right)\biggl(x - b\biggr)}{\left(a - \dfrac{a+b}{2}\right)\biggl(a - b\biggr)} + f\left(\dfrac{a+b}{2}\right) \dfrac{\biggl(x - a\biggr)\biggl(x - b\biggr)}{\left(\dfrac{a+b}{2} - a\right)\left(\dfrac{a+b}{2} - b\right)} + f(b) \dfrac{\biggl(x - a\biggr)\left(x - \dfrac{a+b}{2}\right)}{\biggl(b - a\biggr)\left(b - \dfrac{a+b}{2}\right)}$
    }
\end{equation}
%
Utilizing integration by substitution, \cref{eqn:lagrange_smps_ab} can be integrated into the form expressed in \cref{eqn:smps_rule}, which is the equation for Simpson's Rule.
%
\begin{gather*}
    \int_a^b P(x) dx = \dfrac{b - a}{6} \left[f(a) + 4f\left(\dfrac{a + b}{2}\right) + f(b)\right]                                  \\
    \dfrac{b - a}{2} = h                                                                                                            \\
\end{gather*}
\vspace*{-1.2cm}
\begin{align*}
    \int_a^b P(x) dx &= \dfrac{h}{3} \left[f(a) + 4f\left(\dfrac{a + b}{2}\right) + f(b)\right]                                     \\
    \int_a^b P(x) dx &\approx \int_a^b f(x) dx                                                                                      \\
    \int_a^b f(x) dx &\approx \dfrac{h}{3} \left[f(a) + 4f\left(\dfrac{a + b}{2}\right) + f(b)\right]  \tageq\label{eqn:smps_rule}
\end{align*}
%
\cref{eqn:smps_rule} gives an approximate value for the integral of the subinterval using a single polynomial function.
Like in the Trapezoid and Rectangle rules~(see \cref{eqn:trap_rule,eqn:rect_rule}), the interval can be split into smaller subintervals in order to increase accuracy.
Expressed mathematically, the equation for the approximate value of the interval as a whole is equal to the sum of the values of each subinterval, the equation of which takes the form of \cref{eqn:composite_smps_rule}.
%
\begin{equation}
    \label{eqn:composite_smps_rule}
    \int_a^b f(x) dx \approx \dfrac{h}{3} \sum_{j=1}^{n / 2} \biggl[f(x_{2j-2}) + 4f(x_{2j-1}) + f(x_{2j})\biggr]
\end{equation}
%
%\cref{eqn:composite_smps_rule} can be expressed in the form of \cref{eqn:smplfd_composite_smps_rule} for computational efficiency.
%
%\begin{equation}
%    \label{eqn:smplfd_composite_smps_rule}
%    \int_a^b f(x) dx \approx \dfrac{h}{3} \left[f(a) + 4 \sum_{j=1}^{n / 2} f(x_{2j-2}) + 2  \sum_{j=1}^{n / 2 - 1} f(x_{2j}) + f(b)\right]
%\end{equation}
%
\subsection{Effectiveness}
\label{sec:effectiveness}
\subsubsection{Simple Function}
\label{sec:simple}
The effectiveness of the trapezoid rule and the composite Simpson's 1/3 rule can be seen in \cref{fig:trap_rule,fig:smps_rule}.
Even with the relatively large subinterval size, these methods are effective, because the function has no fluctuations that the method would not account for with the subinterval count being used.
Because the methods only sample a few points of the integrand, however, if these few points are not representative of the integrand over the subinterval, neither method will not effectively approximate the integral value.
This means that, although both methods are effective at fitting the curve of a relatively simple function such as a polynomial with relatively few subintervals, they get significantly less effective the more complex the integrand.

\subsubsection{Complex Function}
\label{sec:complex_examples}
Had the integrand been more complex, as in \cref{fig:smps_rule_complex_low}, the area enclosed by the fluctuations would not have been taken into account by either rule.
%
%\subfile{graphs/complex/low/trap_complex_low}
\subfile{graphs/complex/low/smps_complex_low}
%
The only way to improve the accuracy of the estimate is to increase the number of subintervals as in \cref{fig:smps_rule_complex_high}.
The issue with this, however, is that---no matter the method---a large amount of subintervals requires a large amount of computing power.
By scaling the number of subintervals by a factor of \(n\), the number of calculations required also scales linearly by \(n\).
%
%\subfile{graphs/complex/high/trap_complex_high}
\subfile{graphs/complex/high/smps_complex_high}
%
Moreover, although increasing the subinterval count is necessary and effective for complex portions of the integrand, it is inefficient and unnecessary for the portions of the integrand that are relatively simple.
This means our methodology should seek to maximize subinterval count when necessary, and, in all other circumstances, minimize subintervals.

\section{Adaptive Quadrature}
\label{sec:adaptive}
Adaptive Quadrature is the process of changing the width of each subinterval depending on the complexity of the function within each subinterval.
An easy-to-implement process for this calculates the values of both the trapezoid and composite Simpson's 1/3 rules for the current subinterval, compares the two, and---should they significantly differ---splits the subinterval in two and repeats the process.~\autocite[p. 1]{established}
I seek to propose an alternative means of calculating a complexity value and to compare the computational efficiency and accuracy of the two methods.

\subsection{My Method}
\label{sec:my_method}
Because 2nd degree polynomials---which Simpson's 1/3 Rule uses---fit consistent curves well and only encounter difficulty when the curve changes over the course of the subinterval~(see \cref{fig:concavities}), my function for complexity will operate via detecting changes in curvature.
In order to accomplish this, my function~(see \cref{eqn:complexity}) finds the absolute value of the difference between the second derivatives of the two bounds.
%
\subfile{graphs/concavity/concavity}
%
\begin{equation}
    \label{eqn:complexity}
    c(x) = \left|\sder{f(b)} - \sder{f(a)}\right|
\end{equation}
%
The value of calculating using \cref{eqn:complexity} is then---similarly to in the established method---compared to a defined threshold value, and if it exceeds it, the subdivision is split in two and the process is repeated for each.

An example of two steps in this process is shown below in \cref{fig:my_adpt_stepone,fig:my_adpt_steptwo}. The numbers above each subinterval represent \(\Delta\sder{f(x)}\), and the threshold for subdivision is a complexity of \(2.000\).
%
\subfile{graphs/steps/my_method/first_step}
\subfile{graphs/steps/my_method/second_step}

\subsection{Comparison}
\label{sec:comparison}
In order to compare the two methods, I created a program that obtains the subdivision bounds, calculates the integral, and calculates the error as a percentage.
\crefrange{lst:rust_functions}{lst:rust_composite} show the main functions that make this program function.
%
\subfile{code/functions}
\subfile{code/helpers}
\subfile{code/rules}
\subfile{code/composite}
%
The two methods, in terms of number of operations per subinterval are extremely similar. The primary only difference between the two is that the established method calls the trapezoid rule~(see \cref{lst:rust_rules}), while my method calls the complexity function~(see \cref{lst:rust_helpers}).
Even within the two methods called, the number of operations perfomed is extremely similar.
In the trapezoid rule function, two calls to the function \(f(x)\) are made and four additional arithmatic operations are performed.
On the other hand, using the complexity function, two calls to the function \(f(x)\) are made, and seven additional arithmatic operations are performed.
This means that per subinterval, my method performs three more arithmetic operations than the existing method.
Although this is proportional to the number of subintervals, considering the extreme speed of an arithmetic operation, there is very little difference in performance between the methods.
The major downside to my method is that it requires the user to calculate the second derivative by hand before using the method.

\subsubsection{Example Program Usage --- Normal Distribution}
\label{sec:normal}
The function I am using to test and compare both methods is a standard normal distribution as defined by \cref{eqn:normal}.
A normal distribution is a good function to test quadrature on as it is impossible to integrate using the Fundamental Theorem of Calculus, and must be solved using quadrature.
One effect that this has, however, is that error percentages cannot be 100\% correct, as the "correct value" has to be generated using quadrature as well.
In order to mitigate this issue, the value considered "correct" was calculated with the composite simpsons rule with \(10,000\) subintervals.
%
\begin{equation}
    \label{eqn:normal}
    f(x) = \dfrac{10}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}}
\end{equation}
%
In order to use my method, the second derivative of \cref{eqn:normal} must be calculated and hard coded into my program as in \cref{lst:rust_functions}.
%
\begin{align*}
    \der{f(x)} &= \dfrac{10}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}} \cdot \der{-\dfrac{x^2}{2}}\\
    &= \dfrac{10}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}} \cdot \left(-\dfrac{1}{2} \cdot 2x\right)\\
    &= -x \cdot \dfrac{10}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}}\\
    \der{f(x)} &= -x \cdot f(x)
\end{align*}
\begin{align*}
    \sder{f(x)} &= \der{-x \cdot f(x)}\\
    &= (-x) \cdot \der{f(x)} + \der{-x} \cdot f(x)\\
    &= (-x) \cdot (-x \cdot f(x)) + (-1) \cdot f(x)\\
    &= -x^2f(x) + -f(x)\\
    &= f(x)(x^2-1)\\
    \sder{f(x)} &= \dfrac{10(x^2 - 1)}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}} \tageq\label{eqn:2nd_derivative_normal}
\end{align*}
%
Using the program, my method and the established method subdivide the function as shown in \cref{fig:my_adpt_subdiv,fig:other_adpt_subdiv} respectively.
%
\subfile{graphs/adaptive/my_method/subdivisions}
\subfile{graphs/adaptive/other_method/subdivisions}
%
These subdivisions make sense for each method, as my method increases the subintervals while the curvature is changing from concave-up to concave-down and vice versa, while the established method increases the subintervals any time that \textbf{either} the Trapezoid Rule or Simpson's Rule does not perform well.
Since the Trapezoid Rule does not perform well at the most curved sections and Simpson's Rule does, it is logical that those sections would have the most disparity between the two rules' values, and thus be the most subdivided.
It is hard to compare the overall accuracy of the two methods, as the thresholds are completely different, but I've picked two thresholds that have a similar number of subdivisions.
When calculating the enclosed area of the interval \(-4\) to \(4\), using a threshold of \(0.002\) for the established method gave a value of \(9.999367\), which has an error of \(0.000210\%\), while using a threshold of \(0.4\) for my method gave a value of \(9.999754\), which has an error of \(0.004082\%\).

Suprisingly, in this case my method was less accurate than the existing method, despite using 30 more arithmetic operations.
In addition, my method required the manual calculation of the second derivative of the integrand.

\section{Conclusion}
\label{sec:conclusion}

\newpage
\thispagestyle{empty}
\listoffigures
\vspace{1cm}
\listofsnippets
\vspace{1cm}
\phantomsection
\addcontentsline{toc}{section}{References}
\printbibliography
\end{document}
